# Extra Materials

Extra materials.

* Урок про Desicion Trees на scikit-learn.org [link](http://scikit-learn.org/stable/modules/tree.html)
* Python and Kaggle: Feature selection, multiple models and Grid Search [link](http://miguelmalvarez.com/2015/02/23/python-and-kaggle-feature-selection-multiple-models-and-grid-search/)
* How to Tune Algorithm Parameters with Scikit-Learn [link](http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)
* Логические алгоритмы классификации – К. В. Воронцов [link](http://www.machinelearning.ru/wiki/images/9/97/Voron-ML-Logic-slides.pdf)
* Документация по модулю Grid Search на scikit-learn.org [link](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)
* Soft K-means – коротко, строго и одновременно понятно [link](http://cs.gmu.edu/~kosecka/cs803/soft-kmeans.pdf)
* Объяснение градиента (видео) от Andrej Karpathy, отрывок из лекции курса CS231n [link](https://www.youtube.com/watch?v=qlLChbHhbg4&feature=youtu.be&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&t=50m16s)
* Подробнее о градиентном бустинге и особенностях его применения к деревьям [link](http://www.machinelearning.ru/wiki/images/7/7e/Sem03_ensembles_2014.pdf)
* Deep Learning - Ian Goodfellow, Yoshua Bengio, and Aaron Courville (2016) [link](http://www.deeplearningbook.org)
* Подробнее о логистической регрессии и предсказании вероятностей с ее помощью [link](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem10_linear.pdf)
* Метод опорных векторов [link](http://statistica.ru/local-portals/data-mining/metod-opornykh-vektorov/)
* Neural Networks and Deep Learning – ещё одна бесплатная онлайн-книга [link](http://neuralnetworksanddeeplearning.com/index.html)
* Вывод SVM - Заметки оригинального стэнфордского курса Andrew Ng [link](http://cs229.stanford.edu/notes/cs229-notes3.pdf)
* Ещё о выводе градиентного бустинга для регрессии и классификации [link](http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf)
* Grid search and cross-validated estimators на scipy-lectures.org [link](http://www.scipy-lectures.org/packages/scikit-learn/#grid-search-and-cross-validated-estimators)
* Лекции по искусственным нейронным сетям — К. В. Воронцов [link](http://www.ccas.ru/voron/download/NeuralNets.pdf)
* Если хочется на русском, то можно начать с лекций Константина Вячеславовича Воронцова по машинному обучению. Но решающие деревья в этом случае лучше изучить по User Guide scikit-learn, а градиентный бустинг и случайный лес — все-таки по The elements of statistical learning [link](http://machinelearning.ru/wiki/index.php?title=Машинное_обучение_%28курс_лекций%2C_К.В.Воронцов%29)
* Семинары по решающим деревьям – Е. Соколов [link](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem04_trees.pdf)
* Семинары по выбору моделей и критериев качества [link](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem05_metrics.pdf)
* Методичка по методам спуска и градиентам [link](http://www.apmath.spbu.ru/ru/staff/grigorieva/mfk.pdf)
* Подробнее о градиентах и градиентном спуске [link](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem07_linear.pdf)